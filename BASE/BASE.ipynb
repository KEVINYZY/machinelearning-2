{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理论基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于记录一些机器学习中用到公式概念,方便日后查阅,同时也加深记忆,  \n",
    "至少可以让自己知道有这么个东西,用到再详细查资料.而不是脑袋空空."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目录:  \n",
    "\n",
    ">[混淆矩阵](#混淆矩阵)  \n",
    ">[精确率/召回率/F1-Measure](#精确率/召回率/F1-Measure)  \n",
    ">[准确率](#准确率)  \n",
    ">[AUC和ROC](#AUC和ROC)  \n",
    ">[RPC](#RPC)  \n",
    ">[偏差和方差](#偏差和方差)  \n",
    ">[欠拟合和过拟合](#欠拟合和过拟合)  \n",
    ">[正态分布](#正态分布)  \n",
    ">[卡方分布](#卡方分布)  \n",
    ">[平均值](#平均值)  \n",
    ">[标准差和方差](#标准差和方差)  \n",
    ">[殴氏距离](#欧氏距离)  \n",
    ">[余弦距离](#余弦距离)  \n",
    ">[皮尔逊相关度](#皮尔逊相关度)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混淆矩阵\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[python + sklearn ︱分类效果评估——acc、recall、F1、ROC、回归、距离](http://blog.csdn.net/sinat_26917383/article/details/75199996?locationNum=3&fps=1)  \n",
    "混淆矩阵如图1分别用”0“和”1“代表负样本和正样本.  \n",
    "TN(真阴性)代表实际标签为0,预测标签为0的样本数量.  \n",
    "FN(假阴性)代表实际标签为1,但预测标签为0的样本数量.  \n",
    "FP(假阳性)代表实际标签为0,但预测标签为1的样本数量.  \n",
    "TP(真阳性)代表实际标签为1,预测标签为1的样本数量.    \n",
    "预测决定后面的阴阳,预测为0就是阴,1就是阳  \n",
    "预测是否正确决定前面的真假,正确为 真  不正确为假  \n",
    "![混淆矩阵](images/confusionmatrix.png)\n",
    "例子:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "true=[1,1,1,0,0,1]\n",
    "pred=[1,0,1,1,0,0]\n",
    "confusion_matrix(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明:列为真实标签,行为预测标签\n",
    "输出的含义为:  \n",
    "\n",
    "\n",
    "真实\\预测|预测为0|预测为1  \n",
    "------------ | ------------- | ------------ | -------------  \n",
    "真实为0|1|1  \n",
    "真实为1|2|2  \n",
    "\n",
    "从表中可以看出  \n",
    "真实为0 预测为 0的数量为 1 (预测对的)    \n",
    "真实为0 预测为 1的数量为 1 (预测错的)  \n",
    "真实为1 预测为 0的数量为 2 (预测错的)  \n",
    "真实为1 预测为 1的数量为 2 (预测对的)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精确率/召回率/F1-Measure\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精确率(precision)/召回率(recall)/F1-Measure  \n",
    "对应上面的例子:   \n",
    "精确率(precision) **P**=正阳性/预测为阳性的=TP/(TP+FP)=2/(1+2)  \n",
    "召回率(recall) **R**=正阳性/所有真实为1=TP/(FN+TP)=2/(2+2)  \n",
    "F1-Measure:  \n",
    "$$F1 =\\frac{2*R*P}{P+R}$$\n",
    "$$\\frac{2}{F1}=\\frac{1}{P}+\\frac{1}{R}$$\n",
    "\n",
    "理解:  \n",
    "精确率是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。  \n",
    "召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。  \n",
    "P和R指标有时候会出现的矛盾的情况，比如只预测1个并且预测中了,那精确率是100%,但是召回率很低.我们全部都预测为正样本,那么召回率是100%,但是精确率很低.这样就需要综合考虑他们，最常见的方法就是F-Measure，通过计算F值来评价一个指标！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精确率:0.666667\n",
      "召回率:0.500000\n",
      "F1值:0.571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "true=[1,1,1,0,0,1]\n",
    "pred=[1,0,1,1,0,0]\n",
    "print(\"精确率:%f\"%precision_score(true,pred))\n",
    "print(\"召回率:%f\"%recall_score(true,pred))\n",
    "print(\"F1值:%f\"%f1_score(true,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以输出分类报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     class0       0.33      0.50      0.40         2\n",
      "     class1       0.67      0.50      0.57         4\n",
      "\n",
      "avg / total       0.56      0.50      0.51         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names=[\"class0\",\"class1\"]\n",
    "true=[1,1,1,0,0,1]\n",
    "pred=[1,0,1,1,0,0]\n",
    "print(classification_report(true,pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准确率\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率(accuracy)  \n",
    "为了不和上面精确率混淆单独说明\n",
    "对应上面的例子:  \n",
    "准确率(accuracy)=预测对的/所有=(TP+TN)/(TP+FP+TN+FN)=(1+2)/(1+1+2+2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "true=[1,1,1,0,0,1]\n",
    "pred=[1,0,1,1,0,0]\n",
    "accuracy_score(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC和ROC   \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC(Receiver Operating Characteristic) 是TPR vs FPR的曲线  \n",
    "$$TPR=\\frac{TP}{TP+FN}$$\n",
    "所有真实为1中 预测为1的比例\n",
    "$$FPR=\\frac{FP}{TN+FP}$$\n",
    "所有真实为0中 预测为1的比例  \n",
    "ROC曲线如下:  \n",
    "![](images/ROC.png)\n",
    "\n",
    "其曲线下方的面积就是AUC取值一般在0.5到1之间,调模型时可以只看AUC,面积越大越好.曲线越接近左上角模型就越好.至于曲线如何画出来的可以看[ROC和AUC介绍以及如何计算AUC](http://alexkong.net/2013/06/introduction-to-auc-and-roc/)  \n",
    "当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。如果ROC是光滑的，那么基本可以判断没有太大的overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRC\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PR曲线（Precision-Recall curve）和ROC曲线类似，ROC曲线是FPR和TPR的点连成的线，PR曲线是准确率和召回率的点连成的线，如下图所示:  \n",
    "![](images/PRC.png)  \n",
    "\n",
    "在正负样本分布得极不均匀(highly skewed datasets)的情况下，PRC比ROC能更有效地反应分类器的好坏。来自[知乎](https://www.zhihu.com/question/30643044)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 偏差和方差\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在忽略噪声的情况下，泛化误差可分解为偏差、方差两部分。  \n",
    "偏差：度量学习算法的期望预测与真实结果的偏离程度，也叫拟合能力。  \n",
    "方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动造成的影响。\n",
    "\n",
    "---摘自《机器学习》，周志华\n",
    "\n",
    "**偏差(Bias)**：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，如下图第二行所示。\n",
    "\n",
    "**方差(Variance)**：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，如下图右列所示。\n",
    "![](images/biasVariance.png)\n",
    "\n",
    "KNN算法在增大k时，偏差会变大，但RF增大树的数目时偏差却保持不变，GBDT在增大树的数目时偏差却又能变小。\n",
    "\n",
    "high bias 欠拟合  \n",
    "high variance 过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 欠拟合和过拟合  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[欠拟合、过拟合及其解决方法](https://blog.csdn.net/willduan1/article/details/53070777)  \n",
    "**欠拟合**  \n",
    "首先欠拟合就是模型没有很好地捕捉到数据特征，不能够很好地拟合数据，例如下面的例子：\n",
    "![](images/underfitting.png)\n",
    "左图表示size与prize关系的数据，中间的图就是出现欠拟合的模型，不能够很好地拟合数据，如果在中间的图的模型后面再加一个二次项，就可以很好地拟合图中的数据了，如右面的图所示。\n",
    "\n",
    "解决方法：\n",
    "\n",
    "1）添加其他特征项，有时候我们模型出现欠拟合的时候是因为特征项不够导致的，可以添加其他特征项来很好地解决。例如，“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到意想不到的效果。除上面的特征之外，“上下文特征”、“平台特征”等等，都可以作为特征添加的首选项。\n",
    "\n",
    "2）添加多项式特征，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。例如上面的图片的例子。\n",
    "\n",
    "3）减少正则化参数，正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。\n",
    "\n",
    "\n",
    "**过拟合**\n",
    "通俗一点地来说过拟合就是模型把数据学习的太彻底，以至于把噪声数据的特征也学习到了，这样就会导致在后期测试的时候不能够很好地识别数据，即不能正确的分类，模型泛化能力太差。例如下面的例子。\n",
    "![](images/overfitting.png)\n",
    "上面左图表示size和prize的关系，我们学习到的模型曲线如右图所示，虽然在训练的时候模型可以很好地匹配数据，但是很显然过度扭曲了曲线，不是真实的size与prize曲线。\n",
    "\n",
    "\n",
    "\n",
    "解决方法：\n",
    "\n",
    "1）重新清洗数据，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。\n",
    "\n",
    "2）增大数据的训练量，还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。\n",
    "\n",
    "3）采用正则化方法。正则化方法包括L0正则、L1正则和L2正则，而正则一般是在目标函数之后加上对于的范数。但是在机器学习中一般使用L2正则，下面看具体的原因。\n",
    "\n",
    "L0范数是指向量中非0的元素的个数。L1范数是指向量中各个元素绝对值之和，也叫“稀疏规则算子”（Lasso regularization）。两者都可以实现稀疏性，既然L0可以实现稀疏，为什么不用L0，而要用L1呢？个人理解一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光和万千宠爱转于L1范数。\n",
    "\n",
    "L2范数是指向量各元素的平方和然后求平方根。可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0。L2正则项起到使得参数w变小加剧的效果，但是为什么可以防止过拟合呢？一个通俗的理解便是：更小的参数值w意味着模型的复杂度更低，对训练数据的拟合刚刚好（奥卡姆剃刀），不会过分拟合训练数据，从而使得不会过拟合，以提高模型的泛化能力。还有就是看到有人说L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题（具体这儿我也不是太理解）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正态分布\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[高斯分布](http://www.baike.com/wiki/高斯分布)  \n",
    "正态分布又叫高斯分布\n",
    "其概率密度函数为:  \n",
    "![](images/GaussianCurve.png)\n",
    "其中 $\\mu$ 是数学期望  $\\sigma^2$ 是方差 \n",
    "当 $\\mu=0,\\sigma=1$时为标准正态分布  \n",
    "Python中经常使用numpy的Random模块生成正常分布的随机变量  \n",
    "numpy.random.normal(mu, sigma, sampleNo )  \n",
    "第一个参数为 期望 第二个为标准差(方差开根好) 第三个参数为 数量  \n",
    "也可以使用   \n",
    "numpy.random.randn生成标准正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卡方分布\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n个独立同分布的随机变量，都服从正态分布，那么平方和服从的分布就是自由度为n的卡方分布."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均值\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均值就是均值(mean),所有数相加除以个数就得到平均值.  \n",
    "numpy中可以使用 numpy.mean()求均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准差和方差\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方差定义:数据与平均数之差平方和的平均数  \n",
    "$$\\sigma^2=\\frac{\\sum(X-\\mu)^2}{N}$$\n",
    "其中 $\\sigma^2$为总体方差,X为变量,$\\mu$为总体均值,N为总体例数\n",
    "方差是实际值与期望值之差平方的平均值，而标准差是方差算术平方根.  \n",
    "标准差就是上面公式中的 $\\sigma$   \n",
    "意义:当数据分布比较分散（即数据在平均数附近波动较大）时，各个数据与平均数的差的平方和较大，方差就较大；当数据分布比较集中时，各个数据与平均数的差的平方和较小。因此方差越大，数据的波动越大；方差越小，数据的波动就越小  \n",
    "下面是使用numpy求标准差的两种方式,方差就是标准差的平方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41421356237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=[1,2,3,4,5]\n",
    "print(np.std(a))\n",
    "np.sqrt((np.sum(np.power(a-np.mean(a),2))/len(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 欧氏距离\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在N维欧氏空间中$X_1$与$X_2$的距离公式为:  \n",
    "$$d=\\sqrt{\\sum(X_{i1}-X_{i2})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 余弦距离\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "余弦距离又叫余弦相似性 \n",
    "严格来讲余弦距离不是距离，而只是相似性。其他距离直接测量两个高维空间上的点的距离，如果距离为0则两个点“相同”，但余弦的结果为1，只能确定两者高度相似。\n",
    "\n",
    "从几何上看，n维向量空间的一条线段作为底边和原点组成的三角形，其顶角大小是不确定的。对于两条空间向量，即使两点距离一定，他们的夹角余弦值也可以随意变化。\n",
    "\n",
    "假设两用户只对两件商品评分，向量分别为(3,3)和(5,5)，这两位用户的认知其实是一样的，但是欧式距离给出的解显然没有余弦值合理。\n",
    "\n",
    "相对于标准化后的欧式距离，余弦距离少了将数据投影到一个均值为0的区间里这一步骤。对于点X和点Y，其余弦距离： \n",
    "$$d=\\frac{\\sum_{i=1}^{N}x_iy_i}{\\sqrt{\\sum x_i^2}\\sqrt{\\sum y_i^2}}$$\n",
    "\n",
    "余弦距离在给文本分类的词袋模型中使用，例如给一篇文章一共出现过6000个词；因此用一个6000维度的向量X表示这篇文章，每个维度代表字出现数目。另外一篇文章也恰好只出现了这6000字并用向量Y表示该文章，则这两篇文章相似度可以用余弦距离来测量。  \n",
    "优点：余弦距离根据向量方向重合度来判断向量相似度，不受样本   \n",
    "缺点：没有对每个维度进行0均值化处理，如在图片分类中一张图片受光照影响后，前后的余弦距离可能就非常大了。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 皮尔逊相关度\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[相似度的算法（欧几里德距离和皮尔逊算法）](https://blog.csdn.net/u010095372/article/details/53932077)\n",
    "\n",
    "皮尔逊相关系数是比欧几里德距离更加复杂的可以判断人们兴趣的相似度的一种方法。该相关系数是判断两组数据与某一直线拟合程序的一种试题。它在数据不是很规范的时候，会倾向于给出更好的结果。\n",
    "\n",
    "它得出来的系数就在-1和1之间，也就是不相似和相似的程度\n",
    "\n",
    "![](images/pearson1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求导/求偏导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泰勒公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 牛顿法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拟牛顿法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K折验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卡方检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据挖掘算法4组件\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据挖掘算法解构为四个组件：  \n",
    "1）模型结构（函数形式，如线性模型），  \n",
    "2）评分函数(又叫目标函数,损失函数)（评估模型拟合数据的质量，如似然函数，误差平方和，误分类率），  \n",
    "3）优化和搜索方法（评分函数的优化和模型参数的求解），  \n",
    "4）数据管理策略（优化和搜索时对数据的高效访问）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 特征选择和降维\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征选择：原有特征选择出子集，不改变原来的特征空间  \n",
    "降维：将原有的特征重组成为包含信息更多的特征，改变了原有的特征空间  \n",
    "降维的主要方法\n",
    "1. Principal Component Analysis(主成分分析)  \n",
    "2. Singular Value Decomposition(奇异值分解)  \n",
    "3. Sammon’s Mapping(Sammon映射)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征选择的方法  \n",
    "**Filter方法**\n",
    "\n",
    "1. Chi-squared test(卡方检验)  \n",
    "2. information gain(信息增益)，详细可见“简单易学的机器学习算法——决策树之ID3算法”  \n",
    "3. correlation coefficient scores(相关系数)  \n",
    "\n",
    "\n",
    "**Wrapper方法**  \n",
    "    其主要思想是：将子集的选择看作是一个搜索寻优问题，生成不同的组合，对组合进行评价，再与其他的组合进行比较。这样就将子集的选择看作是一个是一个优化问题，这里有很多的优化算法可以解决，尤其是一些启发式的优化算法，如GA，PSO，DE，ABC等，详见“优化算法——人工蜂群算法(ABC)”，“优化算法——粒子群算法(PSO)”。  \n",
    "**Embedded方法**  \n",
    "    其主要思想是：在模型既定的情况下学习出对提高模型准确性最好的属性。这句话并不是很好理解，其实是讲在确定模型的过程中，挑选出那些对模型的训练有重要意义的属性。\n",
    "主要方法：正则化，可以见“简单易学的机器学习算法——岭回归(Ridge Regression)”，岭回归就是在基本线性回归的过程中加入了正则项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征选择的工程方法**:  \n",
    "数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已\n",
    "1. 计算每一个特征与响应变量的相关性：工程上常用的手段有计算皮尔逊系数和互信息系数，皮尔逊系数只能衡量线性相关性而互信息系数能够很好地度量各种相关性，但是计算相对复杂一些，好在很多toolkit里边都包含了这个工具（如sklearn的MINE），得到相关性之后就可以排序选择特征了；  \n",
    "2. 构建单个特征的模型，通过模型的准确性为特征排序，借此来选择特征；  \n",
    "3. 通过L1正则项来选择特征：L1正则方法具有稀疏解的特性，因此天然具备特征选择的特性，但是要注意，L1没有选到的特征不代表不重要，原因是两个具有高相关性的特征可能只保留了一个，如果要确定哪个特征重要应再通过L2正则方法交叉检验*；  \n",
    "4. 训练能够对特征打分的预选模型：RandomForest和Logistic Regression等都能对模型的特征打分，通过打分获得相关性后再训练最终模型；  \n",
    "5. 通过特征组合后再来选择特征：如对用户id和用户特征最组合来获得较大的特征集再来选择特征，这种做法在推荐系统和广告系统中比较常见，这也是所谓亿级甚至十亿级特征的主要来源，原因是用户数据比较稀疏，组合特征能够同时兼顾全局模型和个性化模型，这个问题有机会可以展开讲。  \n",
    "6. 通过深度学习来进行特征选择：目前这种手段正在随着深度学习的流行而成为一种手段，尤其是在计算机视觉领域，原因是深度学习具有自动学习特征的能力，这也是深度学习又叫unsupervised feature learning的原因。从深度学习模型中选择某一神经层的特征后就可以用来进行最终目标模型的训练了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
