{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 招商信用卡_消费金融场景下的用户购买预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比赛网址: http://www.datafountain.cn/?u=7610684&&#/competitions/287/intro  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:19:31.805601Z",
     "start_time": "2018-07-14T15:19:31.290009Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # to import csv and for data manipulation\n",
    "import matplotlib.pyplot as plt # to plot graph\n",
    "import seaborn as sns # for intractve graphs\n",
    "import numpy as np # for linear algebra\n",
    "import datetime # to dela with date and time\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler # for preprocessing the data\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest classifier\n",
    "from sklearn.tree import DecisionTreeClassifier # for Decision Tree classifier\n",
    "from sklearn.svm import SVC # for SVM classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split # to split the data\n",
    "from sklearn.model_selection import KFold # For cross vbalidation\n",
    "from sklearn.model_selection import GridSearchCV # for tunnig hyper parameter it will use all combination of given parameters\n",
    "from sklearn.model_selection import RandomizedSearchCV # same for tunning hyper parameter but will use random combinations of parameters\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "basepath=\"/home/linzhenpeng/Documents/python_workspace/pycharm/project/招商银行/\"\n",
    "datapath=basepath+\"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:19:31.964567Z",
     "start_time": "2018-07-14T15:19:31.807026Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict(data):\n",
    "    time_date = time.strftime('%Y-%m-%d',time.localtime(time.time()))\n",
    "    train = data[data['FLAG']!=-1]\n",
    "    test = data[data['FLAG']==-1]\n",
    "    \n",
    "    train=train.fillna(0)\n",
    "    test=test.fillna(0)\n",
    "    \n",
    "    \n",
    "#     os = SMOTE(random_state=0)\n",
    "\n",
    "#     data_train_X=train.ix[:,train.columns != \"FLAG\"]\n",
    "#     data_train_y=train.ix[:,train.columns == \"FLAG\"]\n",
    "#     columns = data_train_X.columns\n",
    "#     os_data_X,os_data_y=os.fit_sample(data_train_X,data_train_y)\n",
    "#     os_data_X = pd.DataFrame(data=os_data_X,columns=columns)\n",
    "#     os_data_y= pd.DataFrame(data=os_data_y,columns=[\"FLAG\"])\n",
    "#     train2=pd.concat([os_data_X,os_data_y],axis=1)\n",
    "#     train2=train2[train2[\"FLAG\"]==1].sample(300)\n",
    "# #     train_0=train[train[\"FLAG\"]==0].sample((int)(train.shape[0]*0.8))\n",
    "# #     train_1=train[train[\"FLAG\"]==1]\n",
    "#     train=pd.concat([train,train2],axis=0)\n",
    "#     train=train.sample(frac=1).reset_index(drop=True)    \n",
    "    \n",
    "    train_userid = train.pop('USRID')\n",
    "    y = train.pop('FLAG')\n",
    "    col = train.columns\n",
    "    X = train[col].values\n",
    "\n",
    "\n",
    "    test_userid = test.pop('USRID')\n",
    "    test_y = test.pop('FLAG')\n",
    "    test = test[col].values\n",
    "\n",
    "    N = 5\n",
    "    skf = StratifiedKFold(n_splits=N,shuffle=False,random_state=1314)\n",
    "\n",
    "    xx_cv = []\n",
    "    xx_pre = []\n",
    "    df_imp=[]\n",
    "\n",
    "    for train_in,test_in in skf.split(X,y):\n",
    "        X_train,X_test,y_train,y_test = X[train_in],X[test_in],y[train_in],y[test_in]\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        # create dataset for lightgbm\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "        # specify your configurations as a dict\n",
    "#         params = {\n",
    "#             'boosting_type': 'gbdt',\n",
    "#             'objective': 'binary',\n",
    "#             'metric': {'auc'},\n",
    "#             'num_leaves': 32,\n",
    "#             'learning_rate': 0.01,\n",
    "#             'feature_fraction': 0.9,\n",
    "#             'bagging_fraction': 0.8,\n",
    "#             'bagging_freq': 5\n",
    "# #             'verbose': 0\n",
    "#         }\n",
    "        params = {\n",
    "               'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': {'auc'},\n",
    "                'num_leaves':21,\n",
    "                'max_depth':3,\n",
    "                'max_bin':20,\n",
    "                'min_data_in_leaf':95,\n",
    "                'feature_fraction': 0.3,\n",
    "                'bagging_fraction':  0.8,\n",
    "                'bagging_freq': 20,\n",
    "                'lambda_l1':0.7,\n",
    "                'lambda_l2':0.6,\n",
    "                'min_split_gain':1.0\n",
    "                }\n",
    "\n",
    "        print('Start training...')\n",
    "        # train\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=40000,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        verbose_eval=250,\n",
    "                        early_stopping_rounds=50)\n",
    "\n",
    "        # print('Save model...')\n",
    "        # save model to file\n",
    "        # gbm.save_model('model.txt')\n",
    "\n",
    "        print('Start predicting...')\n",
    "        y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "        xx_cv.append(roc_auc_score(y_test,y_pred))\n",
    "        xx_pre.append(gbm.predict(test, num_iteration=gbm.best_iteration))\n",
    "        \n",
    "        \n",
    "#         df = pd.DataFrame(train.columns.tolist(), columns=['feature'])\n",
    "#         df['importance']=list(gbm.feature_importance())                           # 特征分数\n",
    "#         df = df.sort_values(by='importance',ascending=False)                      # 特征排序\n",
    "#         df.to_csv(basepath+'feature/feature_score_%s.csv'%(str(time_date)),index=None,encoding='gbk')  # 保存分数\n",
    "#         df_imp=df[df[\"importance\"]!=0].feature.values\n",
    "#         print(df_imp)\n",
    "    \n",
    "#     data=data.ix[:,df_imp]\n",
    "#     train_predict(data,True)\n",
    "\n",
    "    s = 0\n",
    "    for i in xx_pre:\n",
    "        s = s + i\n",
    "\n",
    "    s = s /N\n",
    "\n",
    "    res = pd.DataFrame()\n",
    "    res['USRID'] = list(test_userid.values)\n",
    "    res['RST'] = list(s)\n",
    "\n",
    "    print('xx_cv',np.mean(xx_cv))\n",
    "\n",
    "    res.to_csv(basepath+'submit/%s_%s.csv'%(str(time_date),str(np.mean(xx_cv)).split('.')[1]),index=False,sep='\\t')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:19:35.221618Z",
     "start_time": "2018-07-14T15:19:31.965841Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取个人信息\n",
    "train_agg = pd.read_csv(datapath+'train_agg.csv',sep='\\t')\n",
    "test_agg = pd.read_csv(datapath+'test_agg.csv',sep='\\t')\n",
    "agg = pd.concat([train_agg,test_agg],copy=False)\n",
    "\n",
    "# 日志信息\n",
    "train_log = pd.read_csv(datapath+'train_log.csv',sep='\\t')\n",
    "test_log = pd.read_csv(datapath+'test_log.csv',sep='\\t')\n",
    "log = pd.concat([train_log,test_log],copy=False)\n",
    "\n",
    "# 用户唯一标识\n",
    "train_flg = pd.read_csv(datapath+'train_flg.csv',sep='\\t')\n",
    "test_flg = pd.read_csv(datapath+'submit_sample.csv',sep='\\t')\n",
    "test_flg['FLAG'] = -1\n",
    "del test_flg['RST']\n",
    "flg = pd.concat([train_flg,test_flg],copy=False)\n",
    "\n",
    "data = pd.merge(agg,flg,on=['USRID'],how='left',copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:20:35.112952Z",
     "start_time": "2018-07-14T15:19:35.223033Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log['time']=log['OCC_TIM'].apply(lambda x:time.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "log['mktime'] = log['time'].apply(lambda x:time.mktime(x))\n",
    "log['days']=log[\"OCC_TIM\"].apply(lambda x:x.split(\" \")[0])\n",
    "log['hours']=log[\"OCC_TIM\"].apply(lambda x:x.split(\" \")[1].split(\":\")[0])\n",
    "log['EVT_LBL_1'] = log['EVT_LBL'].apply(lambda x:x.split('-')[0])\n",
    "log['EVT_LBL_2'] = log['EVT_LBL'].apply(lambda x:x.split('-')[1])\n",
    "log['EVT_LBL_3'] = log['EVT_LBL'].apply(lambda x:x.split('-')[2])\n",
    "log['EVT_LBL_12'] = log['EVT_LBL'].apply(lambda x:x.split('-')[0]+\"-\"+x.split('-')[1])\n",
    "\n",
    "log_l1=log[log[\"days\"]==\"2018-03-31\"]\n",
    "log_l2=log[log[\"days\"]>=\"2018-03-30\"]\n",
    "log_l3=log[log[\"days\"]>=\"2018-03-29\"]\n",
    "log_l5=log[log[\"days\"]>=\"2018-03-27\"]\n",
    "log_l7=log[log[\"days\"]>=\"2018-03-25\"]\n",
    "log_l10=log[log[\"days\"]>=\"2018-03-21\"]\n",
    "log_l15=log[log[\"days\"]>=\"2018-03-15\"]\n",
    "log_l20=log[log[\"days\"]>=\"2018-03-10\"]\n",
    "log_p3=log[log[\"days\"]<=\"2018-03-03\"]\n",
    "log_p7=log[log[\"days\"]<=\"2018-03-07\"]\n",
    "log_p10=log[log[\"days\"]<=\"2018-03-10\"]\n",
    "\n",
    "\n",
    "d1 = datetime.datetime(2018,4,1)\n",
    "log[\"hd\"]=log[\"time\"].apply(lambda x:(d1-datetime.datetime(x.tm_year,x.tm_mon,x.tm_mday)).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:36:44.763681Z",
     "start_time": "2018-07-14T15:36:33.765465Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = log.sort_values(['USRID','mktime'])\n",
    "log['next_time'] = log.groupby(['USRID'])['mktime'].diff(-1).apply(np.abs)\n",
    "log_next_time = log.groupby(['USRID'],as_index=False)['next_time'].agg({\n",
    "    'next_time_mean':np.mean,\n",
    "    'next_time_std':np.std,\n",
    "    'next_time_min':np.min,\n",
    "    'next_time_max':np.max\n",
    "})\n",
    "log_next_time[\"have_log\"]=1\n",
    "data2=pd.merge(data,log_next_time,on=[\"USRID\"],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:36:46.936010Z",
     "start_time": "2018-07-14T15:36:46.752788Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用户总点击\n",
    "user_total_count=log.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_count'))\n",
    "\n",
    "# user_total_count=log_l1.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_l1_count'))\n",
    "\n",
    "# user_total_count=log_l2.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_l2_count'))\n",
    "\n",
    "user_total_count=log_l3.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_l3_count'))\n",
    "\n",
    "# user_total_count=log_l5.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_l5_count'))\n",
    "\n",
    "user_total_count=log_l7.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_l7_count'))\n",
    "\n",
    "# user_total_count=log_l10.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_l10_count'))\n",
    "\n",
    "# user_total_count=log_l15.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_l5_count'))\n",
    "\n",
    "# user_total_count=log_l20.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_l20_count'))\n",
    "\n",
    "# user_total_count=log_p3.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_p3_count'))\n",
    "\n",
    "# user_total_count=log_p7.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_p7_count'))\n",
    "\n",
    "# user_total_count=log_p10.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "# data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_user_total_p10_count'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:36:51.027762Z",
     "start_time": "2018-07-14T15:36:48.888188Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#各天的活跃次数以及权重\n",
    "user_count=pd.crosstab(log[\"USRID\"],log[\"days\"])\n",
    "user_count1=user_count.copy()\n",
    "user_count[\"max\"]=user_count1.max(axis=1)\n",
    "user_count[\"act_days\"]=(user_count1 != 0).sum(axis=1)\n",
    "user_count[\"std\"]=user_count1.std(axis=1)\n",
    "user_count[\"mean\"]=user_count1.mean(axis=1)\n",
    "user_count1=user_count1.apply(lambda x:x*math.exp(int(x.name.split(\"-\")[2])))\n",
    "user_count['day_all_weight']=user_count1.sum(axis=1)\n",
    "# user_count[\"have_log\"]=1\n",
    "# user_count=user_count.ix[:,[\"day_all_weight\",\"USRID\",\"max\",\"act_days\",\"std\",\"mean\",\"have_log\"]]\n",
    "data2=pd.merge(data2,user_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_day_user_count'))\n",
    "\n",
    "user_count=pd.crosstab(log_l3[\"USRID\"],log_l3[\"days\"])\n",
    "user_count1=user_count.copy()\n",
    "user_count[\"max_3\"]=user_count1.max(axis=1)\n",
    "user_count[\"act_days_3\"]=(user_count1 != 0).sum(axis=1)\n",
    "user_count[\"std_3\"]=user_count1.std(axis=1)\n",
    "user_count[\"mean_3\"]=user_count1.mean(axis=1)\n",
    "user_count1=user_count1.apply(lambda x:x*math.exp(int(x.name.split(\"-\")[2])-25))\n",
    "user_count['day_3_weight']=user_count1.sum(axis=1)\n",
    "user_count=user_count.ix[:,[\"day_3_weight\",\"USRID\",\"max_3\",\"act_days_3\",\"std_3\",\"mean_3\"]]\n",
    "data2=pd.merge(data2,user_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_day_user_l3_count'))\n",
    "\n",
    "user_count=pd.crosstab(log_l7[\"USRID\"],log_l7[\"days\"])\n",
    "user_count1=user_count.copy()\n",
    "user_count[\"max_7\"]=user_count1.max(axis=1)\n",
    "user_count[\"act_days_7\"]=(user_count1 != 0).sum(axis=1)\n",
    "user_count[\"std_7\"]=user_count1.std(axis=1)\n",
    "user_count[\"mean_7\"]=user_count1.mean(axis=1)\n",
    "user_count1=user_count1.apply(lambda x:x*math.exp(int(x.name.split(\"-\")[2])-20))\n",
    "user_count['day_7_weight']=user_count1.sum(axis=1)\n",
    "user_count=user_count.ix[:,[\"day_7_weight\",\"USRID\",\"max_7\",\"act_days_7\",\"std_7\",\"mean_7\"]]\n",
    "data2=pd.merge(data2,user_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_day_user_l7_count'))\n",
    "\n",
    "# user_count=pd.crosstab(log_p7[\"USRID\"],log_p7[\"days\"])\n",
    "# user_count1=user_count.copy()\n",
    "# user_count[\"max_p7\"]=user_count1.max(axis=1)\n",
    "# user_count[\"act_days_p7\"]=(user_count1 != 0).sum(axis=1)\n",
    "# user_count[\"std_p7\"]=user_count1.std(axis=1)\n",
    "# user_count[\"mean_p7\"]=user_count1.mean(axis=1)\n",
    "# user_count1=user_count1.apply(lambda x:x*math.exp(int(x.name.split(\"-\")[2])))\n",
    "# user_count['day_p7_weight']=user_count1.sum(axis=1)\n",
    "# user_count=user_count.ix[:,[\"day_p7_weight\",\"USRID\",\"max_p7\",\"act_days_p7\",\"std_p7\",\"mean_p7\"]]\n",
    "# data2=pd.merge(data2,user_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_day_user_p7_count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:36:53.294537Z",
     "start_time": "2018-07-14T15:36:52.889580Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用户在不同设备上的点击次数\n",
    "tch_type=pd.crosstab([log[\"USRID\"]],log[\"TCH_TYP\"],dropna=False)\n",
    "data2 = pd.merge(data2,tch_type,left_on=['USRID'],how='left',right_index=True,copy=False,suffixes=('', '_tch_type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:37:00.434259Z",
     "start_time": "2018-07-14T15:36:55.108950Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#最大点击间隔\n",
    "user_last_touch=log.groupby([\"USRID\"])[\"mktime\"].apply(lambda x:x.max()-x.min())\n",
    "data2 = pd.merge(data2,user_last_touch.to_frame(),left_on=['USRID'],how='left',right_index=True,copy=False,suffixes=('', '_user_last_touch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:37:05.750286Z",
     "start_time": "2018-07-14T15:37:02.282974Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#最后操作距离4月1号的天数\n",
    "user_last_touch=log.groupby([\"USRID\"])[\"hd\"].apply(lambda x:x.min())\n",
    "data2 = pd.merge(data2,user_last_touch.to_frame(),left_on=['USRID'],how='left',right_index=True,copy=False,suffixes=('', '_user_last_day'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:37:11.543533Z",
     "start_time": "2018-07-14T15:37:07.585022Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl_1=pd.crosstab(log[\"USRID\"],log[\"EVT_LBL_1\"])\n",
    "data2=pd.merge(data2,lbl_1,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_lbl_1'))\n",
    "lbl_2=pd.crosstab(log[\"USRID\"],log[\"EVT_LBL_2\"])\n",
    "data2=pd.merge(data2,lbl_2,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_lbl_2'))\n",
    "# lbl_3=pd.crosstab(log[\"USRID\"],log[\"EVT_LBL_3\"])\n",
    "# data2=pd.merge(data2,lbl_3,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_lbl_3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:37:25.889333Z",
     "start_time": "2018-07-14T15:37:13.510877Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#重点页面处理1724,3614,4285,3744,3768,3765          \n",
    "#1700,1703,1678,3743,1718\n",
    "# hot_lbl_3=['1724','3614','4285','3744','3768','3765','1700','1703','1678','3743','1718']\n",
    "hot_lbl_3=['1724','3614','4285','3744','3768','3765','1700','1703','1678','3743','1718',\n",
    "           '117','3640','3766','4301','4311','1725','573','1722','565','277','4357','558',\n",
    "           '1523','3862','2637','564','1710','3769','3622','3248','3623','1677','914','2206',\n",
    "           '3751','3619','2640','3838','3864','3807','1525','2004','4282','2005','2003','559',\n",
    "           '2078','1197','2044','2204','1196','4329','562','3772','3494','3620','566','910',\n",
    "           '3767','4300','1694','1699','4325','17','4303','3771','2052','3834','3121','4326',\n",
    "           '3843','4391','891','3830','1711','3929','4309','3845','4302','19','1712','1728',\n",
    "           '1726','3795','3759','3847','1709','3927','2207','4376','3496','3498','2074',\n",
    "           '4278','3617','1707','43','2043','1708','3745','1701','3819','3801','3813','3805',\n",
    "           '1704','3828','4307','1723','3794','3839','3774','3867','2644','2050','3806',\n",
    "           '2058','2062','3615','2073','2205','3808','1729','4366','462','561','912','911',\n",
    "           '905','897','4378','1679','1693']\n",
    "log_hot_lbl_3=log.query(\"EVT_LBL_3 in \"+str(hot_lbl_3))\n",
    "\n",
    "user_total_count=log_hot_lbl_3.groupby(\"USRID\").agg({\"USRID\":\"count\"})\n",
    "data2=pd.merge(data2,user_total_count,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_hot_lbl_3_count'))\n",
    "\n",
    "log_next_time = log_hot_lbl_3.groupby(['USRID'],as_index=False)['next_time'].agg({\n",
    "    'hot_3_next_time_mean':np.mean,\n",
    "    'hot_3_next_time_std':np.std,\n",
    "    'hot_3_next_time_min':np.min,\n",
    "    'hot_3_next_time_max':np.max\n",
    "})\n",
    "data2=pd.merge(data2,log_next_time,on=[\"USRID\"],how='left')\n",
    "\n",
    "user_last_touch=log_hot_lbl_3.groupby([\"USRID\"])[\"hd\"].apply(lambda x:x.min())\n",
    "data2 = pd.merge(data2,user_last_touch.to_frame(),left_on=['USRID'],how='left',right_index=True,copy=False,suffixes=('', '_hot_3_day'))\n",
    "\n",
    "lbl_3=pd.crosstab(log_hot_lbl_3[\"USRID\"],log_hot_lbl_3[\"EVT_LBL_3\"])\n",
    "data2=pd.merge(data2,lbl_3,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_hot_lbl_3'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:38:04.387751Z",
     "start_time": "2018-07-14T15:38:03.930994Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl_1=pd.crosstab(log_l3[\"USRID\"],log_l3[\"EVT_LBL_1\"])\n",
    "data2=pd.merge(data2,lbl_1,left_on=[\"USRID\"],right_index=True,how=\"left\",suffixes=('', '_lbl_3_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:37:27.716404Z",
     "start_time": "2018-07-14T15:37:27.711758Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2[\"V7_0\"]=data2[\"V7\"]+0.02653405368112591\n",
    "data2[\"V7_1\"]=data2[\"V7\"]-0.6554727928211695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:29:39.922560Z",
     "start_time": "2018-07-14T15:29:39.912364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.012931384983863033"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ix[data[\"FLAG\"]==0,\"V17\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:37:29.622988Z",
     "start_time": "2018-07-14T15:37:29.603930Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>573</th>\n",
       "      <th>891</th>\n",
       "      <th>897</th>\n",
       "      <th>905</th>\n",
       "      <th>910</th>\n",
       "      <th>911</th>\n",
       "      <th>912</th>\n",
       "      <th>914</th>\n",
       "      <th>V7_0</th>\n",
       "      <th>V7_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.92554</td>\n",
       "      <td>-0.90689</td>\n",
       "      <td>-1.26634</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>-0.68454</td>\n",
       "      <td>-1.70618</td>\n",
       "      <td>-0.29641</td>\n",
       "      <td>-0.18761</td>\n",
       "      <td>-0.48351</td>\n",
       "      <td>-0.53051</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.269876</td>\n",
       "      <td>-0.951883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.92554</td>\n",
       "      <td>-0.90689</td>\n",
       "      <td>-1.26634</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>-0.68454</td>\n",
       "      <td>-1.70618</td>\n",
       "      <td>0.37601</td>\n",
       "      <td>-0.10030</td>\n",
       "      <td>-0.16694</td>\n",
       "      <td>-0.31897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402544</td>\n",
       "      <td>-0.279463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.92554</td>\n",
       "      <td>-0.90689</td>\n",
       "      <td>-1.26634</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>-0.68454</td>\n",
       "      <td>-1.57176</td>\n",
       "      <td>0.03980</td>\n",
       "      <td>-0.17089</td>\n",
       "      <td>-0.38610</td>\n",
       "      <td>-0.46000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066334</td>\n",
       "      <td>-0.615673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.92554</td>\n",
       "      <td>-0.90689</td>\n",
       "      <td>-1.26634</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>-0.68454</td>\n",
       "      <td>-1.30291</td>\n",
       "      <td>-0.29641</td>\n",
       "      <td>-0.18761</td>\n",
       "      <td>-0.45916</td>\n",
       "      <td>-0.53051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.269876</td>\n",
       "      <td>-0.951883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.92554</td>\n",
       "      <td>-0.90689</td>\n",
       "      <td>-1.26634</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>-0.68454</td>\n",
       "      <td>-1.16849</td>\n",
       "      <td>-0.29641</td>\n",
       "      <td>-0.18761</td>\n",
       "      <td>-0.50786</td>\n",
       "      <td>-0.60103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.269876</td>\n",
       "      <td>-0.951883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        V1       V2       V3      V4       V5       V6       V7       V8  \\\n",
       "0 -1.92554 -0.90689 -1.26634  0.2892 -0.68454 -1.70618 -0.29641 -0.18761   \n",
       "1 -1.92554 -0.90689 -1.26634  0.2892 -0.68454 -1.70618  0.37601 -0.10030   \n",
       "2 -1.92554 -0.90689 -1.26634  0.2892 -0.68454 -1.57176  0.03980 -0.17089   \n",
       "3 -1.92554 -0.90689 -1.26634  0.2892 -0.68454 -1.30291 -0.29641 -0.18761   \n",
       "4 -1.92554 -0.90689 -1.26634  0.2892 -0.68454 -1.16849 -0.29641 -0.18761   \n",
       "\n",
       "        V9      V10    ...     573  891  897  905  910  911  912  914  \\\n",
       "0 -0.48351 -0.53051    ...     1.0  0.0  0.0  0.0  0.0  0.0  1.0  2.0   \n",
       "1 -0.16694 -0.31897    ...     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -0.38610 -0.46000    ...     0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0   \n",
       "3 -0.45916 -0.53051    ...     0.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0   \n",
       "4 -0.50786 -0.60103    ...     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       V7_0      V7_1  \n",
       "0 -0.269876 -0.951883  \n",
       "1  0.402544 -0.279463  \n",
       "2  0.066334 -0.615673  \n",
       "3 -0.269876 -0.951883  \n",
       "4 -0.269876 -0.951883  \n",
       "\n",
       "[5 rows x 433 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:38:20.593078Z",
     "start_time": "2018-07-14T15:38:09.237387Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63999, 452)\n",
      "(16001, 452)\n",
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's auc: 0.853434\n",
      "Start predicting...\n",
      "(64000, 452)\n",
      "(16000, 452)\n",
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.860501\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's auc: 0.860893\n",
      "Start predicting...\n",
      "(64000, 452)\n",
      "(16000, 452)\n",
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's auc: 0.857495\n",
      "Start predicting...\n",
      "(64000, 452)\n",
      "(16000, 452)\n",
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.860211\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's auc: 0.860456\n",
      "Start predicting...\n",
      "(64001, 452)\n",
      "(15999, 452)\n",
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's auc: 0.851884\n",
      "Start predicting...\n",
      "xx_cv 0.856832394653\n"
     ]
    }
   ],
   "source": [
    "result_3=train_predict(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "781px",
    "left": "16px",
    "right": "20px",
    "top": "121px",
    "width": "324px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
